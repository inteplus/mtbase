'''QueenBee concurrency using asyncio and multiprocessing.'''

import multiprocessing as mp
import multiprocessing.connection as mc


from .base import used_cpu_too_much, used_memory_too_much


__all__ = ['QueenBee', 'default_worker_process']


async def wait_for_msg(conn):
    import asyncio
    while not conn.poll(0):
        await asyncio.sleep(0.1)
    return conn.recv()


class Bee:
    '''The base class of a bee.

    A bee is an asynchronous concurrent worker that can communicate with one or more bees via
    message passing. Communication means requesting another bee do to a task and waiting for some
    result, or doing a task for another bee. While doing a task, the bee can request yet another
    bee to do yet another task for it. And so on. All tasks are asynchronous.

    A task that is delegated from one bee to another bee is communicated via 2 or 3 messages. The
    first message `('request', msg_id, ...)` represents a request to do a task from a sending bee
    to a receiving bee. `msg_id` is a 0-based integer generated by the sender. Upon receiving the
    request, the receiver must send an acknowledgment `('acknowledged', msg_id, to_process)` with
    the same `msg_id` and `to_process` is a boolean telling if the receiver will proceed with
    doing the task (True) or if it rejects the request (False). If it proceeds with doing the task,
    upon completing the task, it must send `('result', msg_id, status, ...)` back to the sender.
    'status' can be one of 3 values: 'cancelled', 'raised' and 'done', depending on whether the
    task was cancelled, raised an exception, or completed without any exception. If `status` is
    'cancelled', the next argument in the message can be optionally some description why it was
    cancelled. If `status` is 'raised', the next argument must be an Exception instance. Finally,
    if `status` is 'done' then the next argument is the returning value.

    The bee posesses a number of connections to communicate with other bees. There are some special
    messages apart from messages controlling task delegation above. The first one is
    `('dead', -1, exit_code)` where exit_code is typically a string describing why the bee has
    died. This message is sent to all bees that the dying bee is connected to. It is sent only when
    the bee has finished up tasks and its worker process is about to terminate. The second one
    is `('die', -1)` which represents the sender's wish for the receiver to finish its life. Bees
    are very sensitive, if someone says 'die' they will be very sad, stop accepting new tasks, and
    die as soon as all existing tasks have been completed.

    Each bee comes with its own life cycle, implemented in the async :func:`run`. The user should
    instead override :func:`handle_task_message` to customise the bee's behaviour.

    Parameters
    ----------
    max_concurrency : int
        maximum number of concurrent tasks that the bee handles at a time
    '''


    def __init__(self, max_concurrency: int = 1024):
        self.conn_list = []
        self.conn_alive_list = []
        self.max_concurrency = max_concurrency


    # ----- public -----


    def add_new_connection(self, conn: mc.Connection):
        '''Adds a new connection to the bee's list of connections.'''

        self.conn_list.append(conn)
        self.conn_alive_list.append(True) # the new connection is assumed alive


    async def delegate_task(self, conn_id: int, msg_details: object):
        '''Delegates a task to another bee.

        Parameters
        ----------
        conn_id : int
            the index of the intended connection to which the task is delegated
        msg_details : tuple
            whatever needed to describe the task to be executed by the other bee

        Returns
        -------
        msg : tuple
            returning message in the form `(status, ...)` where `status` is one of 'cancelled',
            'raised' and 'done'
        '''

        # generate new msg id
        msg_id = self.msg_id
        self.msg_id += 1

        # send the request
        conn = self.conn_list[conn_id]
        conn.send(('request', msg_id) + msg_details)
        self.requesting_delegated_task_map[msg_id] = conn_id

        # await for the task to be completed
        from ..aio import yield_control
        while msg_id not in self.done_delegated_task_map:
            await yield_control()

        # get the result
        msg = self.done_delegated_task_map[msg_id]
        del self.done_delegated_task_map[msg_id] # pop it

        return msg


    async def handle_task_message(self, conn_id: int, msg_id: int, msg_details: object):
        '''Handles a request message coming from one of the connecting bees.

        The default behaviour implemented here is to wait for a few seconds and then to raise a
        NotImplementedError.

        Parameters
        ----------
        conn_id : int
            the index pointing to the connection from which the message comes
        msg_id : int
            the message id provided by the sender
        msg_details : object
            usually a tuple of all other data of the message

        Returns
        -------
        object
            user-defined

        Raises
        ------
        Exception
            user-defined
        '''
        import random
        import asyncio

        delay_time = random.randrange(1, 5)
        await asyncio.sleep(delay_time)
        raise NotImplementedError("Implement me.")


    # ----- private -----


    async def run(self):
        '''Implements the life-cycle of a bee. Please do not invoke this function directly.'''

        import asyncio

        self.msg_id = 0
        self.to_terminate = False

        # tasks delegated to other bees
        self.requesting_delegated_task_map = {} # msg_id -> conn_id
        self.pending_delegated_task_map = {} # msg_id -> conn_id
        self.done_delegated_task_map = {} # msg_id -> (status, ...)

        # tasks handled by the bee itself
        self.pending_request_list = [] # (conn_id, msg_id, ...)
        self.working_task_map = {} # task -> (conn_id, msg_id)

        self.await_new_msg_task = asyncio.ensure_future(self.await_new_msg())

        while (self.await_new_msg_task is not None) or self.pending_request_list or self.working_task_map:
            # form the list of current tasks performed by the bee
            task_list = list(self.working_task_map)
            if self.await_new_msg_task is not None:
                task_list.append(self.await_new_msg_task)
            done_task_list, _ = await asyncio.wait(task_list, return_when=asyncio.FIRST_COMPLETED)

            # process each of the tasks done by the bee
            for task in done_task_list:
                if task == self.await_new_msg_task: # got something from a sender?
                    self.process_done_await_new_msg(task)
                else: # one of existing tasks has completed
                    self.process_done_task(task)

            # should we await for a new message?
            if self.await_new_msg_task is None and not self.to_terminate:
                self.await_new_msg_task = asyncio.ensure_future(self.await_new_msg())

            # transform some pending requests into working tasks
            num_requests = min(self.max_concurrency - len(self.working_task_map), len(self.pending_request_list))
            for i in range(num_requests):
                full_msg = self.pending_request_list.pop(0) # (msg_id, ...)
                conn_id = full_msg[0]
                msg_id = full_msg[1]
                task = asyncio.ensure_future(self.handle_task_message(conn_id, msg_id, full_msg[2:]))
                self.working_task_map[task] = (conn_id, msg_id)

        self.inform_death(self.exit_code)


    def process_done_await_new_msg(self, task):
        '''Processes the new message from any of the other alive bees.'''

        self.await_msg_task = None
        if task.cancelled() or task.exception() is not None: # abrupted communication
            self.to_terminate = True
            self.exit_code = 'Abrupted communication.'
            return

        conn_id, full_msg = task.result() # got a message from a sender
        if full_msg[0] == 'die': # request to die?
            self.to_terminate = True
            self.exit_code = "A bee with conn_id={} said 'die'.".format(conn_id)
        elif full_msg[0] == 'dead':
            self.conn_alive_list[conn_id] = False # mark the connection as dead
        elif full_msg[0] == 'request': # new task
            msg_id = full_msg[1]
            conn = self.conn_list[conn_id]
            if self.to_terminate:
                conn.send(('acknowledged', msg_id, False)) # reject the request
            else:
                self.pending_request_list.append((conn_id,) + full_msg[1:])
                conn.send(('acknowledged', msg_id, True))
        elif full_msg[0] == 'acknowledged': # delegated task accepted or not
            msg_id = full_msg[1]
            request_status = full_msg[2]
            conn_id = self.requesting_delegated_task_map[msg_id]
            del self.requesting_delegated_task_map[msg_id] # pop it
            if request_status: # accepted
                self.pending_delegated_task_map[msg_id] = conn_id
            else:
                self.done_delegated_task_map[msg_id] = ('raised', RuntimeError('Delegated task rejected.'))
        elif full_msg[0] == 'result': # delegated task completed
            msg_id = full_msg[1]
            status = full_msg[2]
            conn_id = self.pending_delegated_task_map[msg_id]
            del self.pending_delegated_task_map[msg_id] # pop it
            if status == 'cancelled':
                self.done_delegated_task_map[msg_id] = ('raised', RuntimeError('Delegated task cancelled.'))
            else:
                self.done_delegated_task_map[msg_id] = full_msg[2:]
        else:
            pass # ignore for now


    def process_done_task(self, task):
        '''Processes a task that has been completed by the bee itself.'''

        conn_id, msg_id = self.working_task_map[task]
        del self.working_task_map[task] # pop it
        conn = self.conn_list[conn_id]

        if task.cancelled():
            conn.send(('result', msg_id, 'cancelled'))
        elif task.exception() is not None:
            conn.send(('result', msg_id, 'raised', task.exception()))
        else:
            conn.send(('result', msg_id, 'done', task.result()))


    async def await_new_msg(self):
        '''Awaits for a new message from one of the alive connections.

        Returns
        -------
        conn_id : int
            the index of the connection in the 'conn_list' attribute
        msg : object
            the message received from the connection. It must be a tuple `(str, msg_id, ...)`.
        '''

        import asyncio

        while True:
            for conn_id, conn in self.conn_list:
                if not self.conn_alive_list[conn_id]:
                    continue
                if conn.poll(0): # has data?
                    msg = conn.recv()
                    return conn_id, msg

            await asyncio.sleep(0.1)


    def inform_death(self, exit_code):
        '''Informs all other alive bees that it has died.

        Parameters
        ----------
        exit_code : object
            the dying bee's last word
        '''

        for conn_id, conn in self.conn_list:
            if not self.conn_alive_list[conn_id]:
                continue
            conn.send(('dead', -1, exit_code))


class WorkerBee(Bee):
    '''A worker bee in the queenbee concurrency model.

    The user should implement :func:`handle_task_message` to customise the worker bee.

    See :func:`Bee.handle_task_message` for more details.

    Parameters
    ----------
    conn : multiprocessing.connection.Connection
        a connection to communicate with the queen bee
    profile : str, optional
        the S3 profile from which the context vars are created. See :func:`mt.base.s3.create_context_vars`.
    max_concurrency : int
        maximum number of concurrent tasks that the bee handles at a time

    '''

    def __init__(self, profile, max_concurrency: int = 1024):
        super().__init__(max_concurrency=max_concurrency)
        self.profile = profile
        self.q2w_conn, self.w2q_conn = mp.Pipe()
        self.process = mp.Process(target=self.worker_process, daemon=True)


    async def worker_process_async(self):
        from ..s3 import create_context_vars

        async with create_context_vars(profile=self.profile, asyn=True) as context_vars:
            self.context_vars = context_vars
            self.add_new_connection(self.w2q_conn)

            await self.run()


    def worker_process(self):
        import asyncio
        try:
            asyncio.run(self.worker_process_async())
        except Exception as e:
            self.w2q_conn.send(('killed', e)) # tell queen bee that it has been killed by an unexpected exception


class QueenBee(Bee):
    '''The queenbee concurrency model.

    This is a concurrency model made up by Minh-Tri. In this model, there is one queen bee main
    process and multiple worker bee subprocesses. The queen bee is responsible for spawning and
    destroying worker bees herself. She is also responsible for organisation-level tasks. The
    queen bee communicates with every worker bee using a full-duplex pipe, via a message-passing
    mechanism. She does not do individual-level tasks but instead assigns those tasks to worker
    bees.

    The queenbee model can be useful for applications like making ML model predictions from a
    dataframe. In this case, the queen bee owns access to the ML model and the dataframe, delegates
    the potentially IO-related preprocessing and postprocessing tasks of every row of the dataframe
    to worker bees, and deals with making batch predictions from the model.

    The queen bee and her worker bees work in asynchronous mode. Each worker bee operates within a
    context returned from :func:`mt.base.s3.create_context_vars`, with a given profile. It is asked
    to upper-limit number of concurrent asyncio tasks to a given threshold.

    Upon initialising a queenbee concurrency model, the user must provide a subclass of
    :class:`WorkerBee` to represent the worker bee class, from which the queen can spawn worker bees.
    It is expected that the user override :func:`handle_task_message` to customise the queen bee's
    behaviour in dealing with tasks.

    Parameters
    ----------
    worker_bee_class : class
        a subclass of :class:`WorkerBee`
    profile : str, optional
        the S3 profile from which the context vars are created. See :func:`mt.base.s3.create_context_vars`.
    max_concurrency : int
        the maximum number of concurrent tasks at any time for a worker bee, good for managing
        memory allocations. Non-integer values are not accepted.
    '''

    def __init__(self, worker_bee_class, profile: str = None, max_concurrency: int = 1024):
        self.worker_bee_class = worker_bee_class
        self.profile = profile
        if not isinstance(max_concurrency, int):
            raise ValueError("Argument 'max_concurrency' is not an integer: {}.".format(max_concurrency))
        self.max_concurrency = max_concurrency
        self.worker_list = []


    def spawn_new_worker_bee(self):
        worker_bee = self.worker_bee_class(profile=self.profile, max_concurrency=self.max_concurrency)
        self.worker_list.append(worker_bee)
        self.add_new_connection(worker_bee.q2c_conn)
        return len(self.worker_list)-1 # worker_id
