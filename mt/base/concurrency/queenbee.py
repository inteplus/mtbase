'''QueenBee concurrency using asyncio and multiprocessing.'''

import multiprocessing as mp
import multiprocessing.connection as mc


from .base import used_cpu_too_much, used_memory_too_much


__all__ = ['QueenBee', 'default_worker_process']


async def wait_for_msg(conn):
    import asyncio
    while not conn.poll(0):
        await asyncio.sleep(0.1)
    return conn.recv()


class Bee:
    '''The base class of a bee.

    A bee is an asynchronous concurrent worker that can communicate with one or more bees via
    message passing. Communication means requesting another bee do to a task and waiting for some
    result, or doing a task for another bee. While doing a task, the bee can request yet another
    bee to do yet another task for it. And so on. All tasks are asynchronous.

    Each message is a key-value dictionary. A task that is delegated from one bee to another bee is
    communicated via 2 or 3 messages. The first message
    `{'msg_type': 'request', 'msg_id': int, 'task': str, ...}` represents a request to do a task
    from a sending bee to a receiving bee. `msg_id` is a 0-based integer generated by the sender.
    Upon receiving the request, the receiver must send an acknowledgment
    `{'msg_type': 'acknowledged', 'msg_id': int, 'to_process': bool}` with the same `msg_id` and
    `to_process` is a boolean telling if the receiver will proceed with doing the task (True) or if
    it rejects the request (False). If it proceeds with doing the task, upon completing the task,
    it must send `{'msg_type': 'result', 'msg_id': int, 'status': str, ...}` back to the sender.
    `status` can be one of 3 values: 'cancelled', 'raised' and 'done', depending on whether the
    task was cancelled, raised an exception, or completed without any exception. If `status` is
    'cancelled', then optionally key `reason` tells  why it was cancelled. If `status` is 'raised',
    then key `exception` contains an Exception instance and key `callstack` contains a list of text
    lines describing the call stack, and key `other_details` contains other supporting information.
    Finally, if `status` is 'done', key `returning_value` holds the returning value.

    The bee posesses a number of connections to communicate with other bees. There are some special
    messages apart from messages controlling task delegation above. The first one is
    `{'msg_type': 'dead', 'death_type': str, ...}` where `death_type` is either 'normal' or
    'killed'. If it is normal, key `exit_code` is either None or a string representing an exit code
    or a last word. If it is 'killed', key `exception` holds the Exception that caused the bee to
    be killed, and key `callstack` holds a list of text lines describing the call stack. This
    message is sent to all bees that the dying bee is connected to. It is sent only when the bee
    has finished up tasks and its worker process is about to terminate. The second one is
    `{'msg_type': 'die'}` which represents the sender's wish for the receiver to finish its life
    gracecfully. Bees are very sensitive, if someone says 'die' they will be very sad, stop
    accepting new tasks, and die as soon as all existing tasks have been completed.

    Each bee comes with its own life cycle, implemented in the async :func:`run`. The user should
    instead override :func:`handle_task_message` to customise the bee's behaviour.

    Parameters
    ----------
    max_concurrency : int
        maximum number of concurrent tasks that the bee handles at a time
    '''


    def __init__(self, max_concurrency: int = 1024):
        self.conn_list = []
        self.conn_alive_list = []
        self.max_concurrency = max_concurrency


    # ----- public -----


    def add_new_connection(self, conn: mc.Connection):
        '''Adds a new connection to the bee's list of connections.'''

        self.conn_list.append(conn)
        self.conn_alive_list.append(True) # the new connection is assumed alive


    async def delegate_task(self, conn_id: int, task_details: dict):
        '''Delegates a task to another bee.

        Parameters
        ----------
        conn_id : int
            the index of the intended connection to which the task is delegated
        task_details : dict
            a dictionary containing information about the task. It must have key 'task' which is a
            string describing what task it is.

        Returns
        -------
        task_msg : dict
            returning message in the form `{'status': str, ...}` where `status` is one of
            'cancelled', 'raised' and 'done'. The remaining keys are described in the class
            docstring.
        '''

        # generate new msg id
        msg_id = self.msg_id
        self.msg_id += 1

        # send the request
        conn = self.conn_list[conn_id]
        msg = {'msg_type': 'request', 'msg_id': msg_id}
        msg.update(task_details)
        conn.send(msg)
        self.requesting_delegated_task_map[msg_id] = conn_id

        # await for the task to be completed
        from ..aio import yield_control
        while msg_id not in self.done_delegated_task_map:
            await yield_control()

        # get the result
        task_msg = self.done_delegated_task_map[msg_id]
        del self.done_delegated_task_map[msg_id] # pop it

        return task_msg


    async def handle_task_message(self, conn_id: int, msg_id: int, task_details: dict):
        '''Handles a request message coming from one of the connecting bees.

        The default behaviour implemented here is to wait for a few seconds and then to raise a
        NotImplementedError.

        Parameters
        ----------
        conn_id : int
            the index pointing to the connection from which the message comes
        msg_id : int
            the message id provided by the sender
        task_details : dict
            a dictionary containing information about the task. It must have key 'task' which is a
            string describing what task it is.

        Returns
        -------
        object
            user-defined

        Raises
        ------
        Exception
            user-defined
        '''
        import random
        import asyncio

        delay_time = random.randrange(1, 5)
        await asyncio.sleep(delay_time)
        raise NotImplementedError("Implement me.")


    # ----- private -----


    async def run(self):
        '''Implements the life-cycle of a bee. Please do not invoke this function directly.'''

        import asyncio

        self.msg_id = 0
        self.to_terminate = False

        # tasks delegated to other bees
        self.requesting_delegated_task_map = {} # msg_id -> conn_id
        self.pending_delegated_task_map = {} # msg_id -> conn_id
        self.done_delegated_task_map = {} # msg_id -> {'status': str, ...}

        # tasks handled by the bee itself
        self.pending_request_list = [] # (conn_id, msg_id, {'task': str, ...})
        self.working_task_map = {} # task -> (conn_id, msg_id)

        self.await_new_msg_task = asyncio.ensure_future(self.await_new_msg())

        while (self.await_new_msg_task is not None) or self.pending_request_list or self.working_task_map:
            # form the list of current tasks performed by the bee
            task_list = list(self.working_task_map)
            if self.await_new_msg_task is not None:
                task_list.append(self.await_new_msg_task)
            done_task_list, _ = await asyncio.wait(task_list, return_when=asyncio.FIRST_COMPLETED)

            # process each of the tasks done by the bee
            for task in done_task_list:
                if task == self.await_new_msg_task: # got something from a sender?
                    self.process_done_await_new_msg(task)
                else: # one of existing tasks has completed
                    self.process_done_task(task)

            # should we await for a new message?
            if self.await_new_msg_task is None and not self.to_terminate:
                self.await_new_msg_task = asyncio.ensure_future(self.await_new_msg())

            # transform some pending requests into working tasks
            num_requests = min(self.max_concurrency - len(self.working_task_map), len(self.pending_request_list))
            for i in range(num_requests):
                conn_id, msg_id, task_msg = self.pending_request_list.pop(0) # pop it
                task = asyncio.ensure_future(self.handle_task_message(conn_id, msg_id, task_msg))
                self.working_task_map[task] = (conn_id, msg_id)

        self.inform_death({'death_type': 'normal', 'exit_code': self.exit_code})


    def process_death_wish(self, conn_id, msg): # msg = {'death_type': str, ...}
        '''Processes the death wish of another bee.'''

        from ..traceback import extract_stack_compact

        self.conn_alive_list[conn_id] = False # mark the connection as dead

        # process all pending tasks held up by the dead bee
        for msg_id, other_conn_id in self.requesting_delegated_task_map.items():
            if other_conn_id != conn_id:
                continue
            del self.requesting_delegated_task_map[msg_id] # pop it
            self.done_delegated_task_map[msg_id] = {
                'status': 'raised',
                'exception': RuntimeError('Delegated task rejected as the delegated bee had been killed.'),
                'callstack': extract_stack_compact(),
                'other_details': {
                    'conn_id': conn_id,
                    'last_word_msg': msg,
                },
            }
        for msg_id, other_conn_id in self.pending_delegated_task_map.items():
            if other_conn_id != conn_id:
                continue
            del self.pending_delegated_task_map[msg_id] # pop it
            self.done_delegated_task_map[msg_id] = {
                'status': 'raised',
                'exception': RuntimeError('Delegated task cancelled as the delegated bee had been killed.'),
                'callstack': extract_stack_compact(),
                'other_details': {
                    'conn_id': conn_id,
                    'last_word_msg': msg,
                },
            }


    def process_done_await_new_msg(self, task):
        '''Processes the new message from any of the other alive bees.'''

        from ..traceback import extract_stack_compact

        self.await_msg_task = None
        if task.cancelled() or task.exception() is not None: # abrupted communication
            self.to_terminate = True
            self.exit_code = 'Abrupted communication.'
            return

        conn_id, full_msg = task.result() # got a message from a sender
        msg_type = full_msg['msg_type']
        if msg_type == 'die': # request to die?
            self.to_terminate = True
            self.exit_code = "A bee with conn_id={} said 'die'.".format(conn_id)
        elif msg_type == 'dead':
            self.process_death_wish(conn_id, full_msg)
        elif msg_type == 'request': # new task
            msg_id = full_msg['msg_id']
            conn = self.conn_list[conn_id]
            if self.to_terminate:
                conn.send({'msg_type': 'acknowledged', 'msg_id': msg_id, 'to_process': False}) # reject the request
            else:
                self.pending_request_list.append((conn_id, msg_id, full_msg))
                conn.send({'msg_type': 'acknowledged', 'msg_id': msg_id, 'to_process': True})
        elif msg_type == 'acknowledged': # delegated task accepted or not
            msg_id = full_msg['msg_id']
            request_status = full_msg['to_process']
            conn_id = self.requesting_delegated_task_map[msg_id]
            del self.requesting_delegated_task_map[msg_id] # pop it
            if request_status: # accepted
                self.pending_delegated_task_map[msg_id] = conn_id
            else:
                self.done_delegated_task_map[msg_id] = {
                    'status': 'raised',
                    'exception': RuntimeError('Delegated task rejected.'),
                    'callstack': extract_stack_compact(),
                    'other_details': {'conn_id': conn_id},
                }
        elif msg_type == 'result': # delegated task completed
            msg_id = full_msg['msg_id']
            status = full_msg['status']
            conn_id = self.pending_delegated_task_map[msg_id]
            del self.pending_delegated_task_map[msg_id] # pop it
            if status == 'cancelled':
                self.done_delegated_task_map[msg_id] = {
                    'status': 'raised',
                    'exception': RuntimeError('Delegated task cancelled.'),
                    'callstack': extract_stack_compact(),
                    'other_details': {'conn_id': conn_id, 'reason': full_msg['reason']},
                }
            elif status == 'raised':
                self.done_delegated_task_map[msg_id] = {
                    'status': 'raised',
                    'exception': RuntimeError('Delegated task raised an exception.'),
                    'callstack': extract_stack_compact(),
                    'other_details': {'conn_id': conn_id, 'msg': full_msg},
                }
            else:
                retval = full_msg['returning_value']
                self.done_delegated_task_map[msg_id] = {
                    'status': 'done',
                    'returning_value': retval,
                }
        else:
            self.to_terminate = True
            self.exit_code = "Unknown message with type '{}'.".format(msg_type)


    def process_done_task(self, task):
        '''Processes a task that has been completed by the bee itself.'''

        import io

        conn_id, msg_id = self.working_task_map[task]
        del self.working_task_map[task] # pop it
        conn = self.conn_list[conn_id]

        if task.cancelled():
            conn.send({'msg_type': 'result', 'msg_id': msg_id, 'status': 'cancelled', 'reason': None})
        elif task.exception() is not None:
            tracestack = io.StringIO()
            task.print_stack(file=tracestack)

            conn.send({
                'msg_type': 'result',
                'msg_id': msg_id,
                'status': 'raised',
                'exception': task.exception(),
                'callstack': tracestack.getvalue(),
                'other_details': None,
            })
        else:
            conn.send({
                'msg_type': 'result',
                'msg_id': msg_id,
                'status': 'done',
                'returning_value': task.result(),
            })


    async def await_new_msg(self):
        '''Awaits for a new message from one of the alive connections.

        Returns
        -------
        conn_id : int
            the index of the connection in the 'conn_list' attribute
        msg : object
            the message received from the connection. It must be a tuple `(str, msg_id, ...)`.
        '''

        import asyncio

        while True:
            for conn_id, conn in self.conn_list:
                if not self.conn_alive_list[conn_id]:
                    continue
                if conn.poll(0): # has data?
                    msg = conn.recv()
                    return conn_id, msg

            await asyncio.sleep(0.1)


    def inform_death(self, msg):
        '''Informs all other alive bees that it has died.

        Parameters
        ----------
        msg : dict
            message in the form `{'death_type': str, ...}` where death type can be either 'normal' or 'killed'
        '''

        wrapped_msg = {'msg_type': 'dead'}
        wrapped_msg.update(msg)
        for conn_id, conn in self.conn_list:
            if not self.conn_alive_list[conn_id]:
                continue
            conn.send(wrapped_msg)


class WorkerBee(Bee):
    '''A worker bee in the queenbee concurrency model.

    The user should implement :func:`handle_task_message` to customise the worker bee.

    See :func:`Bee.handle_task_message` for more details.

    Parameters
    ----------
    conn : multiprocessing.connection.Connection
        a connection to communicate with the queen bee
    profile : str, optional
        the S3 profile from which the context vars are created. See :func:`mt.base.s3.create_context_vars`.
    max_concurrency : int
        maximum number of concurrent tasks that the bee handles at a time

    '''

    def __init__(self, profile, max_concurrency: int = 1024):
        super().__init__(max_concurrency=max_concurrency)
        self.profile = profile
        self.q2w_conn, self.w2q_conn = mp.Pipe()
        self.process = mp.Process(target=self.worker_process, daemon=True)


    async def worker_process_async(self):
        from ..s3 import create_context_vars

        async with create_context_vars(profile=self.profile, asyn=True) as context_vars:
            self.context_vars = context_vars
            self.add_new_connection(self.w2q_conn)

            await self.run()


    def worker_process(self):
        import asyncio
        from ..traceback import extract_stack_compact

        try:
            asyncio.run(self.worker_process_async())
        except Exception as e: # tell queen bee that it has been killed by an unexpected exception
            self.w2q_conn.send({
                'msg_type': 'dead',
                'death_type': 'killed',
                'exception': e,
                'callstack': extract_stack_compact(),
            })


class QueenBee(Bee):
    '''The queenbee concurrency model.

    This is a concurrency model made up by Minh-Tri. In this model, there is one queen bee main
    process and multiple worker bee subprocesses. The queen bee is responsible for spawning and
    destroying worker bees herself. She is also responsible for organisation-level tasks. The
    queen bee communicates with every worker bee using a full-duplex pipe, via a message-passing
    mechanism. She does not do individual-level tasks but instead assigns those tasks to worker
    bees.

    The queenbee model can be useful for applications like making ML model predictions from a
    dataframe. In this case, the queen bee owns access to the ML model and the dataframe, delegates
    the potentially IO-related preprocessing and postprocessing tasks of every row of the dataframe
    to worker bees, and deals with making batch predictions from the model.

    The queen bee and her worker bees work in asynchronous mode. Each worker bee operates within a
    context returned from :func:`mt.base.s3.create_context_vars`, with a given profile. It is asked
    to upper-limit number of concurrent asyncio tasks to a given threshold.

    Upon initialising a queenbee concurrency model, the user must provide a subclass of
    :class:`WorkerBee` to represent the worker bee class, from which the queen can spawn worker bees.
    It is expected that the user override :func:`handle_task_message` to customise the queen bee's
    behaviour in dealing with tasks.

    Parameters
    ----------
    worker_bee_class : class
        a subclass of :class:`WorkerBee`
    profile : str, optional
        the S3 profile from which the context vars are created. See :func:`mt.base.s3.create_context_vars`.
    max_concurrency : int
        the maximum number of concurrent tasks at any time for a worker bee, good for managing
        memory allocations. Non-integer values are not accepted.
    '''

    def __init__(self, worker_bee_class, profile: str = None, max_concurrency: int = 1024):
        self.worker_bee_class = worker_bee_class
        self.profile = profile
        if not isinstance(max_concurrency, int):
            raise ValueError("Argument 'max_concurrency' is not an integer: {}.".format(max_concurrency))
        self.max_concurrency = max_concurrency
        self.worker_list = []


    def spawn_new_worker_bee(self):
        worker_bee = self.worker_bee_class(profile=self.profile, max_concurrency=self.max_concurrency)
        self.worker_list.append(worker_bee)
        self.add_new_connection(worker_bee.q2c_conn)
        return len(self.worker_list)-1 # worker_id
